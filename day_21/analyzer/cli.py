from __future__ import annotations

import argparse
import os
from pathlib import Path

from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.console import Console
from rich.progress import (
    Progress,
    SpinnerColumn,
    BarColumn,
    TextColumn,
    TimeElapsedColumn,
)
from openai import OpenAI

from .indexer import ProjectIndexer
from .retriever import Retriever
from .llm import LLMAnalyzer
from .cache import EmbeddingCache
from .reranker import make_reranker


console = Console()


def _add_common_args(parser: argparse.ArgumentParser) -> None:
    parser.add_argument("project_root", type=str, help="–ü—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞")
    parser.add_argument("--exclude-dirs", nargs="*", default=[])
    parser.add_argument("--max-files", type=int, default=None)
    parser.add_argument("--embed-model", type=str, default="text-embedding-3-large")
    parser.add_argument("--llm-model", type=str, default="gpt-4.1")
    parser.add_argument("--top-k", type=int, default=24)
    parser.add_argument("--max-chars", type=int, default=1500)
    parser.add_argument("--overlap", type=int, default=150)
    parser.add_argument("--max-file-bytes", type=int, default=1_500_000)
    parser.add_argument("--max-file-chars", type=int, default=120_000)
    parser.add_argument("--scan-timeout-ms", type=int, default=800)
    parser.add_argument("--max-chunks-per-file", type=int, default=100)
    parser.add_argument("--no-gitignore", action="store_true")
    parser.add_argument(
        "--skip-lockfiles", action=argparse.BooleanOptionalAction, default=True
    )
    parser.add_argument(
        "--skip-minified", action=argparse.BooleanOptionalAction, default=True
    )
    parser.add_argument(
        "--skip-sourcemaps", action=argparse.BooleanOptionalAction, default=True
    )
    parser.add_argument("--verbose-files", action="store_true")
    parser.add_argument("--report-md", type=str, default="analysis_report.md")
    parser.add_argument("--multi-stage", action="store_true")
    parser.add_argument("--module-top-k", type=int, default=36)
    parser.add_argument("--global-top-k", type=int, default=48)
    parser.add_argument("--cache-dir", type=str, default=None)
    parser.add_argument("--no-cache", action="store_true")

    # –ù–æ–≤—ã–π –±–ª–æ–∫ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
    parser.add_argument(
        "--reranker", type=str, default="none", choices=["none", "cohere"]
    )
    parser.add_argument(
        "--preselect-factor",
        type=int,
        default=5,
        help="–í–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —à–∏—Ä–µ –±—Ä–∞—Ç—å –ø—É–ª –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–µ—Ä–µ–¥ —Ä–µ—Ä–∞–Ω–∫–æ–º (>=1)",
    )
    parser.add_argument(
        "--rerank-top-k",
        type=int,
        default=None,
        help="–°–∫–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ —Ä–µ—Ä–∞–Ω–∫–∞ (–µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è top-k)",
    )
    parser.add_argument(
        "--rerank-threshold",
        type=float,
        default=None,
        help="–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç—ã —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞",
    )
    parser.add_argument(
        "--compare-rerank",
        action="store_true",
        help="–°—Ä–∞–≤–Ω–∏—Ç—å baseline vs rerank (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–∞ –æ—Ç—á—ë—Ç–∞ –∏ —Ñ–∞–π–ª —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)",
    )


def main() -> None:
    parser = argparse.ArgumentParser("analyzer")
    _add_common_args(parser)
    args = parser.parse_args()

    root = Path(args.project_root).resolve()
    if not root.exists():
        console.print(f"[red]–ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω:[/] {root}")
        raise SystemExit(2)

    if "OPENAI_API_KEY" not in os.environ:
        console.print("[red]–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY[/]")
        raise SystemExit(1)

    client = OpenAI()

    console.print(Panel.fit(f"üìÅ –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞: [bold]{root}[/]"))

    indexer = ProjectIndexer(
        root=root,
        exclude_dirs=args.exclude_dirs,
        max_files=args.max_files,
        max_file_bytes=args.max_file_bytes,
        max_file_chars=args.max_file_chars,
        scan_timeout_ms=args.scan_timeout_ms,
        max_chunks_per_file=args.max_chunks_per_file,
        skip_lockfiles=args.skip_lockfiles,
        skip_minified=args.skip_minified,
        skip_sourcemaps=args.skip_sourcemaps,
        verbose=args.verbose_files,
        respect_gitignore=not args.no_gitignore,
    )

    chunks = indexer.build_chunks(max_chars=args.max_chars, overlap=args.overlap)
    if not chunks:
        console.print("[red]–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.[/]")
        raise SystemExit(1)

    reports_dir = root / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)

    with Progress(
        SpinnerColumn(),
        TextColumn("[bold]–ó–∞–≥—Ä—É–∑–∫–∞ –∫–µ—à–∞[/]"),
        TimeElapsedColumn(),
        console=console,
    ) as progress:
        task = progress.add_task("llm", total=None)
        cache = (
            None
            if args.no_cache
            else EmbeddingCache(
                Path(args.cache_dir)
                if args.cache_dir
                else root / ".proj_analyzer_cache"
            )
        )
        progress.update(task, completed=1)

    # –†–µ—Ä–∞–Ω–∫–µ—Ä
    rr = make_reranker(args.reranker) if args.reranker != "none" else None

    retriever = Retriever(
        client,
        args.embed_model,
        cache=cache,
        reranker=rr,
        preselect_factor=args.preselect_factor,
        rerank_top_k=args.rerank_top_k,
        rerank_threshold=args.rerank_threshold,
    )
    retriever.embed_chunks(chunks)

    analyzer = LLMAnalyzer(client, args.llm_model, max_ctx_chunks=args.top_k)

    # === –û–¥–Ω–æ—ç—Ç–∞–ø–Ω—ã–π —Ä–µ–∂–∏–º ===
    if not args.multi_stage:
        question = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞ –∏ –Ω–∞–π–¥–∏ –æ—á–µ–≤–∏–¥–Ω—ã–µ –±–∞–≥–∏ –∏ —Ä–∏—Å–∫–∏."

        retriever_baseline = Retriever(client, args.embed_model, cache=cache)
        retriever_baseline.embed_chunks(chunks)

        top_baseline = retriever_baseline.query(chunks, question, top_k=args.top_k)
        top_rerank = retriever.query(chunks, question, top_k=args.top_k)

        md_baseline = analyzer.analyze_single(root, top_baseline)
        md_rerank = analyzer.analyze_single(root, top_rerank)

        if args.compare_rerank and rr is not None:
            (root / "analysis_report_baseline.md").write_text(
                md_baseline, encoding="utf-8"
            )
            (root / "analysis_report_rerank.md").write_text(md_rerank, encoding="utf-8")
            cmp_md = (
                "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–æ–≤\n\n"
                "## Baseline –∏ Rerank\n"
                f"- –†–µ—Ä–∞–Ω–∫–µ—Ä: {getattr(rr, 'name', 'none')}\n"
                f"- –ü–æ—Ä–æ–≥ –æ—Ç—Å–µ—á–µ–Ω–∏—è: {args.rerank_threshold}\n"
                f"- –ü—Ä–µ–¥–≤—ã–±–æ—Ä–∫–∞ (factor): {args.preselect_factor}\n"
                "\n"
                "–§–∞–π–ª—ã:\n"
                "- analysis_report_baseline.md\n"
                "- analysis_report_rerank.md\n"
            )
            (root / "analysis_report_comparison.md").write_text(
                cmp_md, encoding="utf-8"
            )
            console.print(Panel.fit("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã baseline, rerank –∏ comparison."))
        else:
            (root / args.report_md).write_text(
                md_rerank if rr is not None else md_baseline, encoding="utf-8"
            )
            console.print(
                Panel.fit(f"‚úÖ –ì–æ—Ç–æ–≤–æ. –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: [bold]{args.report_md}[/]")
            )
        return

    # === –ú–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π —Ä–µ–∂–∏–º ===
    modules = indexer.detect_modules(chunks)
    module_summaries = []

    for mod_name, mod_chunks in modules.items():
        question_mod = f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–æ–¥—É–ª—å '{mod_name}' –∏ –Ω–∞–π–¥–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã, –±–∞–≥–∏ –∏ —Ä–∏—Å–∫–∏."
        top_mod = retriever.query(mod_chunks, question_mod, top_k=args.module_top_k)
        md_mod = analyzer.analyze_module(root, mod_name, top_mod)
        (reports_dir / f"module_{mod_name}.md").write_text(md_mod, encoding="utf-8")
        module_summaries.append(f"## {mod_name}\n" + md_mod[:1200])

    question_global = "–°—Ñ–æ—Ä–º–∏—Ä—É–π –æ–±—â—É—é –∫–∞—Ä—Ç–∏–Ω—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Ä–∏—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π."
    top_global = retriever.query(chunks, question_global, top_k=args.global_top_k)
    global_md = analyzer.analyze_global(root, "".join(module_summaries), top_global)
    (root / args.report_md).write_text(global_md, encoding="utf-8")
    console.print(
        Panel.fit(f"‚úÖ –ì–æ—Ç–æ–≤–æ. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: [bold]{args.report_md}[/]")
    )
    console.print(Markdown("–ú–æ–¥—É–ª—å–Ω—ã–µ –æ—Ç—á—ë—Ç—ã –ª–µ–∂–∞—Ç –≤ –ø–∞–ø–∫–µ `reports/`."))


if __name__ == "__main__":
    main()
