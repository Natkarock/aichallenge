# 🧠 Dialog Summarization Demo (LangGraph + LangChain)

Демонстрационный CLI-проект, показывающий **сжатие истории диалога** (summarization) при работе с LLM-агентом.

Цель — сравнить два режима работы:
- **без сжатия** — агент хранит всю историю сообщений;
- **со сжатием** — агент каждые N сообщений делает краткое резюме истории и хранит его вместо оригинальных сообщений.

Это снижает расход токенов и позволяет поддерживать длинные разговоры при сохранении контекста.

---

## 🚀 Возможности

- Демонстрация принципа краткосрочной памяти через **саммаризацию**.
- Сравнение расхода токенов в режимах с и без компрессии.
- Отображение прогресса (`rich` спиннеры, таблицы, панели).
- CLI-интерфейс без Streamlit.
- Полностью совместимо с **LangChain 1.x** и **LangGraph 1.x**.
- Работает с моделями OpenAI (например `gpt-4o-mini`, `gpt-4o`, `gpt-3.5-turbo`).

---

## 🧩 Установка

### 1. Клонирование проекта
```bash
git clone https://github.com/yourname/dialog-summarization-demo.git
cd dialog-summarization-demo
```

### 2. Установка зависимостей
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Экспорт API-ключа
```bash
export OPENAI_API_KEY=sk-ВАШ_КЛЮЧ
```

---

## ⚙️ Файлы проекта

```
.
├── main.py           # Основной CLI-скрипт
├── requirements.txt  # Зависимости
└── README.md         # Это описание
```

---

## 🧠 Как работает

Каждый вопрос добавляется в историю сообщений.  
В режиме **без сжатия** история растёт, и модель получает всё больше контекста → растут затраты токенов.

В режиме **со сжатием** каждые `N` сообщений выполняется суммаризация (по умолчанию `N=10`):
- История превращается в компактное резюме (`summary`).
- Сохраняется только последнее сообщение.
- Новый контекст формируется из `summary + последнее сообщение`.

Это имитирует **краткосрочную память** в многоходовом диалоге.

---

## ▶️ Запуск

Запустить оба режима для сравнения:
```bash
python main.py --mode both
```

Только без сжатия:
```bash
python main.py --mode nosummary
```

Только со сжатием:
```bash
python main.py --mode summarize
```

---

## 🧾 Пример вывода

```
─────────────────────────────────────────────────────────────── Режим БЕЗ сжатия ────────────────────────────────────────────────────────────────
Q1: Хочу спроектировать умного агента на Python. С чего начать...
⠇ Генерирую ответ…
╭── Ответ ──╮
│ Начни с проектирования архитектуры: ядро агента, память, инструменты... │
╰───────────╯

...
─────────────────────────────────────────────────────────────── Режим СО сжатием ────────────────────────────────────────────────────────────────
...
╭────────────── Сжатие истории (после Q10) ───────────────╮
│ • агент может вызывать внешние API
│ • память нужна для краткосрочного контекста
│ • LangGraph помогает управлять узлами
│ ...                                                    │
╰──────────────────────────────────────────────────────────╯
...

────────────────────────────────────── Сравнение расхода токенов ───────────────────────────────────────
  Режим        prompt   completion   total
 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  Без сжатия   1259     754          2013
  Со сжатием   640      320          960
Более экономный режим: Со сжатием.
```

---

## ⚖️ Аргументы командной строки

| Аргумент | Описание | Пример |
|-----------|-----------|--------|
| `--mode` | Режим запуска (`both`, `nosummary`, `summarize`) | `--mode both` |
| `--every` | Как часто выполнять суммаризацию (по умолчанию 10) | `--every 5` |
| `--model` | Имя модели OpenAI | `--model gpt-4o-mini` |

---

## 📊 Сравнение режимов

| Режим | Принцип | Контекст растёт? | Затраты токенов | Контекст сохраняется |
|-------|----------|------------------|------------------|----------------------|
| Без сжатия | Полная история сообщений | Да | Высокие | Полный |
| Со сжатием | Резюме + последнее сообщение | Нет | Низкие | Сжатый |

---

